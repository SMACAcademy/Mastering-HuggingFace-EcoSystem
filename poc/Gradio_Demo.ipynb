{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradioNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading gradio-5.13.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
      "  Using cached aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\muthu\\.conda\\envs\\huggingface_env\\lib\\site-packages (from gradio) (4.8.0)\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
      "  Using cached fastapi-0.115.7-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting gradio-client==1.6.0 (from gradio)\n",
      "  Downloading gradio_client-1.6.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\muthu\\.conda\\envs\\huggingface_env\\lib\\site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.25.1 in c:\\users\\muthu\\.conda\\envs\\huggingface_env\\lib\\site-packages (from gradio) (0.27.1)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\muthu\\.conda\\envs\\huggingface_env\\lib\\site-packages (from gradio) (3.1.5)\n",
      "Collecting markupsafe~=2.0 (from gradio)\n",
      "  Downloading MarkupSafe-2.1.5-cp312-cp312-win_amd64.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\muthu\\.conda\\envs\\huggingface_env\\lib\\site-packages (from gradio) (2.2.2)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Downloading orjson-3.10.15-cp312-cp312-win_amd64.whl.metadata (42 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\muthu\\.conda\\envs\\huggingface_env\\lib\\site-packages (from gradio) (24.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\muthu\\.conda\\envs\\huggingface_env\\lib\\site-packages (from gradio) (2.2.3)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\users\\muthu\\.conda\\envs\\huggingface_env\\lib\\site-packages (from gradio) (10.2.0)\n",
      "Collecting pydantic>=2.0 (from gradio)\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting pydub (from gradio)\n",
      "  Using cached pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.18 (from gradio)\n",
      "  Using cached python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\muthu\\.conda\\envs\\huggingface_env\\lib\\site-packages (from gradio) (6.0.2)\n",
      "Collecting ruff>=0.2.2 (from gradio)\n",
      "  Downloading ruff-0.9.3-py3-none-win_amd64.whl.metadata (26 kB)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
      "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
      "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
      "  Using cached tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Using cached typer-0.15.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\muthu\\.conda\\envs\\huggingface_env\\lib\\site-packages (from gradio) (4.12.2)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Using cached uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\muthu\\.conda\\envs\\huggingface_env\\lib\\site-packages (from gradio-client==1.6.0->gradio) (2024.9.0)\n",
      "Collecting websockets<15.0,>=10.0 (from gradio-client==1.6.0->gradio)\n",
      "  Using cached websockets-14.2-cp312-cp312-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\muthu\\.conda\\envs\\huggingface_env\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\muthu\\.conda\\envs\\huggingface_env\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\muthu\\.conda\\envs\\huggingface_env\\lib\\site-packages (from httpx>=0.24.1->gradio) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\muthu\\.conda\\envs\\huggingface_env\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\muthu\\.conda\\envs\\huggingface_env\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\muthu\\.conda\\envs\\huggingface_env\\lib\\site-packages (from huggingface-hub>=0.25.1->gradio) (3.17.0)\n",
      "Requirement already satisfied: requests in c:\\users\\muthu\\.conda\\envs\\huggingface_env\\lib\\site-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\muthu\\.conda\\envs\\huggingface_env\\lib\\site-packages (from huggingface-hub>=0.25.1->gradio) (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\muthu\\.conda\\envs\\huggingface_env\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\muthu\\.conda\\envs\\huggingface_env\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\muthu\\.conda\\envs\\huggingface_env\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.0->gradio)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic>=2.0->gradio)\n",
      "  Using cached pydantic_core-2.27.2-cp312-cp312-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting click>=8.0.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\muthu\\.conda\\envs\\huggingface_env\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\muthu\\.conda\\envs\\huggingface_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\muthu\\.conda\\envs\\huggingface_env\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.15.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\muthu\\.conda\\envs\\huggingface_env\\lib\\site-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\muthu\\.conda\\envs\\huggingface_env\\lib\\site-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.3.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading gradio-5.13.1-py3-none-any.whl (57.6 MB)\n",
      "   ---------------------------------------- 0.0/57.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/57.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.8/57.6 MB 2.1 MB/s eta 0:00:28\n",
      "    --------------------------------------- 1.3/57.6 MB 2.3 MB/s eta 0:00:25\n",
      "   - -------------------------------------- 2.1/57.6 MB 2.7 MB/s eta 0:00:21\n",
      "   - -------------------------------------- 2.6/57.6 MB 2.8 MB/s eta 0:00:20\n",
      "   -- ------------------------------------- 3.7/57.6 MB 3.2 MB/s eta 0:00:18\n",
      "   --- ------------------------------------ 4.7/57.6 MB 3.4 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 5.5/57.6 MB 3.5 MB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 6.3/57.6 MB 3.6 MB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 7.1/57.6 MB 3.5 MB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 7.9/57.6 MB 3.6 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 8.9/57.6 MB 3.7 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 10.0/57.6 MB 3.8 MB/s eta 0:00:13\n",
      "   ------- -------------------------------- 11.0/57.6 MB 3.9 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 11.8/57.6 MB 4.0 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 12.8/57.6 MB 4.0 MB/s eta 0:00:12\n",
      "   --------- ------------------------------ 14.2/57.6 MB 4.1 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 15.2/57.6 MB 4.2 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 16.3/57.6 MB 4.3 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 17.6/57.6 MB 4.3 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 18.6/57.6 MB 4.4 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 19.7/57.6 MB 4.4 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 21.0/57.6 MB 4.5 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 22.0/57.6 MB 4.5 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 23.3/57.6 MB 4.6 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 24.4/57.6 MB 4.6 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 25.4/57.6 MB 4.6 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 26.2/57.6 MB 4.6 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 27.3/57.6 MB 4.6 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 28.0/57.6 MB 4.6 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 29.1/57.6 MB 4.6 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 30.1/57.6 MB 4.6 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 30.7/57.6 MB 4.5 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 31.5/57.6 MB 4.5 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 32.2/57.6 MB 4.5 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 32.8/57.6 MB 4.5 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 33.6/57.6 MB 4.5 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 34.3/57.6 MB 4.4 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 35.1/57.6 MB 4.4 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 35.7/57.6 MB 4.4 MB/s eta 0:00:06\n",
      "   ------------------------- -------------- 36.4/57.6 MB 4.3 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 37.0/57.6 MB 4.3 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 37.5/57.6 MB 4.3 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 38.3/57.6 MB 4.2 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 38.8/57.6 MB 4.2 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 39.6/57.6 MB 4.2 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 40.1/57.6 MB 4.2 MB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 40.9/57.6 MB 4.2 MB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 41.4/57.6 MB 4.1 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 42.2/57.6 MB 4.1 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 43.0/57.6 MB 4.1 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 43.5/57.6 MB 4.1 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 44.3/57.6 MB 4.1 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 45.1/57.6 MB 4.1 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 45.9/57.6 MB 4.1 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 46.4/57.6 MB 4.0 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 46.9/57.6 MB 4.0 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 47.4/57.6 MB 4.0 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 48.0/57.6 MB 4.0 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 48.8/57.6 MB 4.0 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 49.3/57.6 MB 4.0 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 50.1/57.6 MB 3.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 50.9/57.6 MB 3.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 51.4/57.6 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 52.2/57.6 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 53.0/57.6 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 53.5/57.6 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 54.0/57.6 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 54.5/57.6 MB 3.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 55.1/57.6 MB 3.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 55.8/57.6 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  56.4/57.6 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  56.9/57.6 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  57.4/57.6 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 57.6/57.6 MB 3.8 MB/s eta 0:00:00\n",
      "Downloading gradio_client-1.6.0-py3-none-any.whl (321 kB)\n",
      "Using cached aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached fastapi-0.115.7-py3-none-any.whl (94 kB)\n",
      "Downloading MarkupSafe-2.1.5-cp312-cp312-win_amd64.whl (17 kB)\n",
      "Downloading orjson-3.10.15-cp312-cp312-win_amd64.whl (133 kB)\n",
      "Downloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Using cached pydantic_core-2.27.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "Using cached python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading ruff-0.9.3-py3-none-win_amd64.whl (10.8 MB)\n",
      "   ---------------------------------------- 0.0/10.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/10.8 MB 2.8 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 1.0/10.8 MB 3.0 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.8/10.8 MB 3.0 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 2.4/10.8 MB 3.0 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.1/10.8 MB 3.1 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.7/10.8 MB 3.1 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 4.5/10.8 MB 3.2 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 5.2/10.8 MB 3.2 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 5.8/10.8 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 6.6/10.8 MB 3.2 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 7.3/10.8 MB 3.3 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 8.1/10.8 MB 3.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.7/10.8 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.4/10.8 MB 3.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.2/10.8 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.8/10.8 MB 3.4 MB/s eta 0:00:00\n",
      "Downloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
      "Using cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
      "Using cached tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
      "Using cached typer-0.15.1-py3-none-any.whl (44 kB)\n",
      "Using cached uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
      "Downloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
      "Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached websockets-14.2-cp312-cp312-win_amd64.whl (164 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: pydub, websockets, tomlkit, shellingham, semantic-version, ruff, python-multipart, pydantic-core, orjson, mdurl, markupsafe, ffmpy, click, annotated-types, aiofiles, uvicorn, starlette, pydantic, markdown-it-py, safehttpx, rich, gradio-client, fastapi, typer, gradio\n",
      "  Attempting uninstall: markupsafe\n",
      "    Found existing installation: MarkupSafe 3.0.2\n",
      "    Uninstalling MarkupSafe-3.0.2:\n",
      "      Successfully uninstalled MarkupSafe-3.0.2\n",
      "Successfully installed aiofiles-23.2.1 annotated-types-0.7.0 click-8.1.8 fastapi-0.115.7 ffmpy-0.5.0 gradio-5.13.1 gradio-client-1.6.0 markdown-it-py-3.0.0 markupsafe-2.1.5 mdurl-0.1.2 orjson-3.10.15 pydantic-2.10.6 pydantic-core-2.27.2 pydub-0.25.1 python-multipart-0.0.20 rich-13.9.4 ruff-0.9.3 safehttpx-0.1.6 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.45.3 tomlkit-0.13.2 typer-0.15.1 uvicorn-0.34.0 websockets-14.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Muthu\\.conda\\envs\\huggingface_env\\Lib\\site-packages\\~arkupsafe'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "%pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* Running on public URL: https://7f548ecc9ec45ad45a.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://7f548ecc9ec45ad45a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\n",
    "def greet(name):\n",
    "    return \"Hello \" + name\n",
    "\n",
    "\n",
    "# We instantiate the Textbox class\n",
    "textbox = gr.Textbox(label=\"Type your name here:\", placeholder=\"Kumar\", lines=2)\n",
    "\n",
    "gr.Interface(fn=greet, inputs=textbox, outputs=\"text\").launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2eea97516c947bc8370359610e8174e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Muthu\\.conda\\envs\\huggingface_env\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Muthu\\.cache\\huggingface\\hub\\models--openai-community--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6272258195c949ba9e7fbefe033214bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76349d8f145d49868b776a76a0e7874e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec0c0556413a485ba464263c571788ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d5153176304919b3962023755bb1ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1f67bbe4c08485a99368168d94ccb33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade0ee4bcd954373b1a21d1ed3b24c12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model = pipeline(\"text-generation\")\n",
    "\n",
    "\n",
    "def predict(prompt):\n",
    "    completion = model(prompt)[0][\"generated_text\"]\n",
    "    return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"My favorite programming language is the programming language of choice. You can do some amazing things in the language but you have to put in the work that would make it fun for your business. The reason it is so cool is that it's often done by\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"My favorite programming language is\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset file at: .gradio\\flagged\\dataset2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "gr.Interface(fn=predict, inputs=\"text\", outputs=\"text\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Audio.__init__() got an unexpected keyword argument 'source'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 11\u001b[0m\n\u001b[0;32m      7\u001b[0m     reversed_audio \u001b[38;5;241m=\u001b[39m (sr, np\u001b[38;5;241m.\u001b[39mflipud(data))\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reversed_audio\n\u001b[1;32m---> 11\u001b[0m mic \u001b[38;5;241m=\u001b[39m gr\u001b[38;5;241m.\u001b[39mAudio(source\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicrophone\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpeak here...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m gr\u001b[38;5;241m.\u001b[39mInterface(reverse_audio, mic, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mlaunch()\n",
      "File \u001b[1;32mc:\\Users\\Muthu\\.conda\\envs\\huggingface_env\\Lib\\site-packages\\gradio\\component_meta.py:179\u001b[0m, in \u001b[0;36mupdateable.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: Audio.__init__() got an unexpected keyword argument 'source'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gradio as gr\n",
    "\n",
    "\n",
    "def reverse_audio(audio):\n",
    "    sr, data = audio\n",
    "    reversed_audio = (sr, np.flipud(data))\n",
    "    return reversed_audio\n",
    "\n",
    "\n",
    "mic = gr.Audio(source=\"microphone\", type=\"numpy\", label=\"Speak here...\")\n",
    "gr.Interface(reverse_audio, mic, \"audio\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gradio as gr\n",
    "\n",
    "notes = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"]\n",
    "\n",
    "\n",
    "def generate_tone(note, octave, duration):\n",
    "    sr = 48000\n",
    "    a4_freq, tones_from_a4 = 440, 12 * (octave - 4) + (note - 9)\n",
    "    frequency = a4_freq * 2 ** (tones_from_a4 / 12)\n",
    "    duration = int(duration)\n",
    "    audio = np.linspace(0, duration, duration * sr)\n",
    "    audio = (20000 * np.sin(audio * (2 * np.pi * frequency))).astype(np.int16)\n",
    "    return (sr, audio)\n",
    "\n",
    "\n",
    "gr.Interface(\n",
    "    generate_tone,\n",
    "    [\n",
    "        gr.Dropdown(notes, type=\"index\"),\n",
    "        gr.Slider(minimum=4, maximum=6, step=1),\n",
    "        gr.Text(type=\"text\", value=1, label=\"Duration in seconds\"),\n",
    "    ],\n",
    "    \"audio\",\n",
    ").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/wav2vec2-base-960h and revision 22aad52 (https://huggingface.co/facebook/wav2vec2-base-960h).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73f6e8b431de435d96cde2a8040d344c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.60k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Muthu\\.conda\\envs\\huggingface_env\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Muthu\\.cache\\huggingface\\hub\\models--facebook--wav2vec2-base-960h. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecca27c847144a21b8b9164b11b5d589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/378M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1834c2ff6a6e4271b2127c80bbff7148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c55f78fc63e4449ea9d5eaa656826dff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/291 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "243d70d370cb4f679c22a04c84d864a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae6658a3ae3423fad7ee7202a13ba68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/159 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Audio.__init__() got an unexpected keyword argument 'source'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 21\u001b[0m\n\u001b[0;32m     14\u001b[0m     transcription \u001b[38;5;241m=\u001b[39m model(audio)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m transcription\n\u001b[0;32m     18\u001b[0m gr\u001b[38;5;241m.\u001b[39mInterface(\n\u001b[0;32m     19\u001b[0m     fn\u001b[38;5;241m=\u001b[39mtranscribe_audio,\n\u001b[0;32m     20\u001b[0m     inputs\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m---> 21\u001b[0m         gr\u001b[38;5;241m.\u001b[39mAudio(source\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicrophone\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilepath\u001b[39m\u001b[38;5;124m\"\u001b[39m, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m     22\u001b[0m         gr\u001b[38;5;241m.\u001b[39mAudio(source\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupload\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilepath\u001b[39m\u001b[38;5;124m\"\u001b[39m, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m     23\u001b[0m     ],\n\u001b[0;32m     24\u001b[0m     outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     25\u001b[0m )\u001b[38;5;241m.\u001b[39mlaunch()\n",
      "File \u001b[1;32mc:\\Users\\Muthu\\.conda\\envs\\huggingface_env\\Lib\\site-packages\\gradio\\component_meta.py:179\u001b[0m, in \u001b[0;36mupdateable.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: Audio.__init__() got an unexpected keyword argument 'source'"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import gradio as gr\n",
    "\n",
    "model = pipeline(\"automatic-speech-recognition\")\n",
    "\n",
    "\n",
    "def transcribe_audio(mic=None, file=None):\n",
    "    if mic is not None:\n",
    "        audio = mic\n",
    "    elif file is not None:\n",
    "        audio = file\n",
    "    else:\n",
    "        return \"You must either provide a mic recording or a file\"\n",
    "    transcription = model(audio)[\"text\"]\n",
    "    return transcription\n",
    "\n",
    "\n",
    "gr.Interface(\n",
    "    fn=transcribe_audio,\n",
    "    inputs=[\n",
    "        gr.Audio(source=\"microphone\", type=\"filepath\", optional=True),\n",
    "        gr.Audio(source=\"upload\", type=\"filepath\", optional=True),\n",
    "    ],\n",
    "    outputs=\"text\",\n",
    ").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
